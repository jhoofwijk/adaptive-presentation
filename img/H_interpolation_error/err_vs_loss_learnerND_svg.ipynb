{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adaptive\n",
    "import numpy as np\n",
    "import scipy\n",
    "adaptive.notebook_extension()\n",
    "\n",
    "from adaptive.learner.learnerND import triangle_loss, volume, uses_nth_neighbors, curvature_loss_function\n",
    "import holoviews as hv\n",
    "hv.notebook_extension()\n",
    "hv.extension('bokeh')\n",
    "\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curvature_loss_function(beta=0.05):\n",
    "    # XXX: add doc-string!\n",
    "    @uses_nth_neighbors(1)\n",
    "    def curvature_loss(simplex, values, neighbors, neighbor_values):\n",
    "        \"\"\"Compute the curvature loss of a simplex.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        simplex : list of tuples\n",
    "            Each entry is one point of the simplex.\n",
    "        values : list of values\n",
    "            The function values of each of the simplex points.\n",
    "        neighbors : list of tuples\n",
    "            The neighboring points of the simplex, ordered such that simplex[0]\n",
    "            exacly opposes neighbors[0], etc.\n",
    "        neighbor_values : list of values\n",
    "            The function values for each of the neighboring points.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : float\n",
    "        \"\"\"\n",
    "        dim = len(simplex[0]) # the number of coordinates\n",
    "        V_s = volume(simplex)\n",
    "\n",
    "        loss_curvature = triangle_loss(simplex, values, neighbors, neighbor_values)\n",
    "        return ((loss_curvature + beta * V_s ** ((2+dim)/dim)))\n",
    "    return curvature_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(-.5, .5)] * 2\n",
    "def f(xy):\n",
    "    x,y = xy\n",
    "    r = (x**2+y**2)**0.5\n",
    "    return np.exp(- (r-0.3)**2 / 0.03**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(-.5, .5)] * 2\n",
    "def f(xy):\n",
    "    x,y = xy\n",
    "    r = (x**2+y**2)**0.5\n",
    "    return np.sinc(r*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(-.5, .5)] * 2\n",
    "def f(xy):\n",
    "    x,y = xy\n",
    "    r = ((x-0.2)**2+(y-0.4)**2)**0.5\n",
    "    return np.exp(-r**2 / 0.05**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(-.5, .5)] * 2\n",
    "def f(xy):\n",
    "    x,y = xy\n",
    "    r = (x**2+y**2)**0.5\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(-.5, .5)] * 2\n",
    "def f(xy):\n",
    "    x,y = xy\n",
    "    x = x*2\n",
    "    y = y*2\n",
    "    return -np.sin(np.pi*x) * np.exp(- y**2/0.3**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(-.5, .5)] * 2\n",
    "def f(xy):\n",
    "    x,y = xy\n",
    "    return x**2+y**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(-.5, .5)] * 2\n",
    "def f(xy):\n",
    "    x,y = xy\n",
    "    x = x*2\n",
    "    y = y*2\n",
    "    return np.tanh(5*(x+y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(-.5, .5)] * 2\n",
    "def f(xy):\n",
    "    x,y = xy\n",
    "    a = 0.2\n",
    "    return x + np.exp(-(4*(x**2 + y**2) - 0.75**2)**2/a**4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_runner(learner, goal):\n",
    "    learner.xx = []\n",
    "    learner.ls = []\n",
    "    while not goal(learner):\n",
    "        x = learner.ask(1)[0][0]\n",
    "        y = learner.function(x)\n",
    "        learner.tell(x,y)\n",
    "        learner.xx.append(x)\n",
    "        learner.ls.append(learner.loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_err(e, norm=2, bounds=None):\n",
    "    bd = np.transpose(bounds)\n",
    "    x = np.random.random((1000000,len(bd))) * (-np.subtract(*bd)) + bd[0]\n",
    "    I = np.average(np.abs(e(x)) ** norm) \n",
    "    A = np.abs(np.product(np.subtract(*bd)))\n",
    "    return (I * A) ** (1/norm)\n",
    "\n",
    "def get_xy(learner, N):\n",
    "    xx = learner.xx[:N]\n",
    "    yy = [learner.data[x] for x in xx]\n",
    "    return xx, yy\n",
    "\n",
    "def get_interpolation_function(learner, n):\n",
    "    x, y = get_xy(learner, n)\n",
    "    lin = scipy.interpolate.LinearNDInterpolator(x,y)\n",
    "    return lin\n",
    "\n",
    "def get_error_function(learner, n):\n",
    "    ip = get_interpolation_function(learner, n)\n",
    "    return (lambda x: ip(x) - f(x.T))\n",
    "\n",
    "def get_err(learner, n, norm=2, bounds=None):\n",
    "    e = get_error_function(learner, n)\n",
    "    return integrate_err(e, norm, bounds or learner._bbox)\n",
    "\n",
    "def get_errs(ns, learner, norm=2):\n",
    "    return [get_err(learner, n, norm=norm) for n in ns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = curvature_loss_function(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8000\n",
    "learner = adaptive.LearnerND(f, bounds=bounds, loss_per_simplex=loss)\n",
    "simple_runner(learner, goal=lambda l: l.npoints==N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.plot(tri_alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_no_curv = adaptive.LearnerND(f, bounds=bounds, loss_per_simplex=None)\n",
    "simple_runner(learner_no_curv, goal=lambda l: l.npoints==N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner._bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Na = np.unique(np.logspace(0.5, np.log10(N), NP, dtype=int))\n",
    "errs_A = []\n",
    "for n in Na:\n",
    "    loss = learner.ls[n-1]\n",
    "    err = get_err(learner=learner, n=n, norm=1)\n",
    "    errs_A.append(err)\n",
    "    print(n, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs_Anc = []\n",
    "for n in Na:\n",
    "    loss = learner_no_curv.ls[n-1]\n",
    "    err = get_err(learner=learner_no_curv, n=n, norm=1)\n",
    "    errs_Anc.append(err)\n",
    "    print(n, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Nh = np.unique(np.logspace(0.5, np.log10(N**0.5), NP, dtype=int))\n",
    "NH = Nh**2\n",
    "errs_H = []\n",
    "for n in Nh:\n",
    "    ax = [np.linspace(*b, n) for b in bounds]\n",
    "    xx = np.meshgrid(*ax)\n",
    "    x = np.array(list(zip(*[i.flat for i in xx])))\n",
    "    y = f(x.T)\n",
    "\n",
    "    lin = scipy.interpolate.LinearNDInterpolator(x,y)\n",
    "    e = (lambda x: lin(x) - f(x.T))\n",
    "    I = integrate_err(e, norm=1, bounds=bounds)\n",
    "    errs_H.append(I)\n",
    "    print(n**2, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit for adaptive\n",
    "NNN_mask = np.array(Na) > 4000\n",
    "NNN_ok = np.array(Na)[NNN_mask]\n",
    "err_A_ok = np.array(errs_A)[NNN_mask]\n",
    "xx = np.log(NNN_ok-1)\n",
    "yA = np.log(err_A_ok)\n",
    "\n",
    "nn2 = np.logspace(np.log10(100), np.log10(N))\n",
    "p, c = np.polyfit(xx, yA, 1)\n",
    "err_A_f = np.exp(c) * nn2 ** p\n",
    "print(f\"Adaptive: fit: {np.exp(c):.2f} * n ^ {p:.3f}\")\n",
    "\n",
    "c1 = np.polyfit(xx, err_A_ok * NNN_ok, 0)[0]\n",
    "err_A_f2 = c1 * nn2 ** -1\n",
    "print(f\"Adaptive, fixed fit: {c1:.2f} * N ^ -1\\n\")\n",
    "\n",
    "\n",
    "# Fit for adaptive no curv\n",
    "NNN_mask = np.array(Na) > 4000\n",
    "NNN_ok = np.array(Na)[NNN_mask]\n",
    "err_Anc_ok = np.array(errs_Anc)[NNN_mask]\n",
    "xx = np.log(NNN_ok-1)\n",
    "yAnc = np.log(err_Anc_ok)\n",
    "\n",
    "nn2 = np.logspace(np.log10(100), np.log10(N))\n",
    "p, c = np.polyfit(xx, yAnc, 1)\n",
    "err_Anc_f = np.exp(c) * nn2 ** p\n",
    "print(f\"Adaptive no curv: fit: {np.exp(c):.2f} * n ^ {p:.3f}\")\n",
    "\n",
    "c1 = np.polyfit(xx, err_Anc_ok * NNN_ok, 0)[0]\n",
    "err_Anc_f2 = c1 * nn2 ** -1\n",
    "print(f\"Adaptive no curv, fixed fit: {c1:.2f} * N ^ -1\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fit for homogenous\n",
    "NNN_mask = np.array(NH) > 4000\n",
    "NNN_ok = np.array(NH)[NNN_mask]\n",
    "err_H_ok = np.array(errs_H)[NNN_mask]\n",
    "xx = np.log(NNN_ok-1)\n",
    "yH = np.log(err_H_ok)\n",
    "\n",
    "p, c = np.polyfit(xx, yH, 1)\n",
    "err_H_f = np.exp(c) * nn2 ** p\n",
    "print(f\"Homogenous: fit: {np.exp(c):.2f} * n ^ {p:.3f}\")\n",
    "\n",
    "c1 = np.polyfit(xx, err_H_ok * NNN_ok, 0)[0]\n",
    "err_H_f2 = c1 * nn2 ** -1\n",
    "print(f\"Homogenous, fixed fit: {c1:.2f} * N ^ -1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Scatter Curve [logx=True, logy=True, width=500, height=500]\n",
    "%%opts Scatter (marker='o' size=4)\n",
    "\n",
    "hv.Scatter((NNN_ok, err_H_ok * NNN_ok))\n",
    "\n",
    "c1 = np.polyfit(xx, err_H_ok * NNN_ok, 0)\n",
    "\n",
    "c2 = np.average(err_H_ok * NNN_ok)\n",
    "\n",
    "print(c1, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Scatter Curve [logx=True, logy=True, width=500, height=500]\n",
    "%%opts Scatter (marker='o' size=4)\n",
    "\n",
    "\n",
    "(\n",
    "    hv.Scatter((Na, errs_A)).relabel(\"Adaptive\") *\n",
    "    hv.Scatter((NH, errs_H)).relabel(\"Homogenous\") *\n",
    "    \n",
    "    hv.Scatter((NH, errs_H)).relabel(\"Adaptive no curv\") *\n",
    "    \n",
    "    hv.Curve((nn2, err_A_f)).relabel(\"Adaptive fit\")  * \n",
    "    hv.Curve((nn2, err_H_f)).relabel(\"Homogenous fit\") *\n",
    "    \n",
    "    hv.Curve((nn2, err_A_f2)).relabel(\"Adaptive forced\")  * \n",
    "    hv.Curve((nn2, err_H_f2)).relabel(\"Homogenous forced\")\n",
    ").redim(x=\"N points\", y=\"Error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Scatter Curve [logx=True, logy=True, width=500, height=500]\n",
    "%%opts Scatter (marker='o' size=4)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# ax.loglog(nn2, err_A_f)\n",
    "# ax.loglog(nn2, err_H_f)\n",
    "\n",
    "# ax.scatter(Na, errs_A, s=5)\n",
    "# ax.scatter(NH, errs_H, s=5)\n",
    "# \n",
    "\n",
    "ax.loglog(NH, errs_H, marker='o', linewidth=0, markersize=3)\n",
    "ax.loglog(Na, errs_A, marker='o', linewidth=0, markersize=3)\n",
    "ax.loglog(Na, errs_Anc, marker='o', linewidth=0, markersize=3)\n",
    "\n",
    "\n",
    "ax.legend(['Homogeneous', 'Adaptive, curvature loss',  'Adaptive, area loss'])\n",
    "plt.xlabel('Number of points')\n",
    "plt.ylabel('Error')\n",
    "plt.savefig('error.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.figure_factory as FF\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "py.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = learner.points.T\n",
    "Z = [learner.data[tuple(p)] for p in learner.points]\n",
    "tri = scipy.spatial.Delaunay(points=learner.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = FF.create_trisurf(x=X, y=Y, z=Z,\n",
    "                         simplices=tri.simplices)\n",
    "\n",
    "py.iplot(fig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Na, Na * errs_A)\n",
    "plt.plot(NH, NH * errs_H)\n",
    "plt.legend(['Adaptive', 'Homogeneous'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nh**2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
